QueueNumberOfWorkers=60
QueueCapacity=128
ProcessQueue=5000
ProcessResetHours=6

# Miliseconds the queue.put  will wait to look for more data on database 
QueueWait=30000

# Seconds the sql retry will will wait if a connection is lost
# MUST BE WHOLE NUMBERS - no spaces after last number !!!
# IDA.java level - wait between find new tar/7z files.
sql.exception.wait=120
# Individual running log file
sql.exception.wait.log=30
# the number of times either the log or file processor will retry for connection
sql.exception.retry=6

extract.directory=/pabbto/3rdparty/ETL/ida/xtract/
inbound.directory=/pabbto/3rdparty/ETL/ida/inbound/
exception.directory=/pabbto/3rdparty/ETL/ida/xcpt/
secure.directory=/pabbto/3rdparty/ETL/svcaddidaetl/secure/

server.port=10302
server.name=ua00475p

# The date range (compared to epoch date on file)
# Key date must be between (epoch date - min days) and (epoch date + max days)
# Note: The min days must be coordinated with the Purge table days limit.
#       If the Purge days limit is greater than the min days - the process
#       will allow records to be added that will be deleted by the purge process 
record.date.minimum.days=365
record.date.maximum.days=4

# runstats flag is used (when Y) to gather optimizer stats on t$ temp tables.
# when this is set to Y - only 1 file should be processed at a time a full
# set of logs and a qcr
runstats=N

# This format corresponds to the date format the DAO objects expect the date 
# to be formatted in
system.date.format=dd-MMM-yyyy HH:mm:ss
REPORTED_RESULT=(\"REPORTED_RESULT\" :)(.*)(,)
JSON_TOGGLE=true

java.executable=/pabbto/3rdparty/ETL/svcaddidaetl/JAVA/bin/java
java.option=-cp
java.class.path=/pabbto/3rdparty/ETL/svcaddidaetl/bin/IDA.jar:/pabbto/3rdparty/ETL/svcaddidaetl/bin/IDA_lib/*
java.parameter1=-Xmx512M 
# java.parameter1=-Xms64M -Xmx256M -XX:+UseCompressedOops

# mutliprocess.program=actions.ProcessFileContents
mutliprocess.program=com.abbott.ida.etl.actions.ProcessFileContents

toshibaDevices=Japan:Korea:Taiwan

# jdbc.driverClassName=oracle.jdbc.OracleDriver
# jdbc.url=jdbc:oracle:thin:@auohsabbt01.oracleoutsourcing.com:1521:pabbto
# jdbc.url=jdbc:oracle:thin:@(DESCRIPTION= (LOAD_BALANCE=on) (ADDRESS=(PROTOCOL=TCP)(HOST=scan-abbt-02.oracleoutsourcing.com)(PORT=1521)) (CONNECT_DATA=(SERVICE_NAME=pabbto))))

# jdbc.url=jdbc:oracle:thin:@(DESCRIPTION= (LOAD_BALANCE=on) (ADDRESS=(PROTOCOL=TCP)(HOST=scan-abbt-02.oracleoutsourcing.com)(PORT=1521)) (CONNECT_DATA=(SERVICE_NAME=pabbto_etl))))
jdbc.url=jdbc:oracle:thin:@(DESCRIPTION= (LOAD_BALANCE=on) (ADDRESS=(PROTOCOL=TCP)(HOST=ux00147p-scan.oneabbott.com)(PORT=1521)) (CONNECT_DATA=(SERVICE_NAME=pabbto_etl))))

jdbc.username=idaconnect


# Set root logger level to DEBUG and its only appender to A1.
# log4j.rootLogger=ERROR, A1, A2


# A1 is set to be a ConsoleAppender.
# log4j.appender.A1=org.apache.log4j.ConsoleAppender

# A1 uses PatternLayout.
# log4j.appender.A1.layout=org.apache.log4j.PatternLayout
# log4j.appender.A1.layout.ConversionPattern=%d{ABSOLUTE} [%t] %-5p %c %x - %m%n

# A2 is set to be a FileAppender
# log4j.appender.A2=org.apache.log4j.RollingFileAppender
# log4j.appender.A2.File=/pabbto/3rdparty/ETL/ida/logs/IDLA_log4j.log 
# log4j.appender.A2.MaxFileSize=20MB 
# log4j.appender.A2.MaxBackupIndex=10

# A2 uses PatternLayout.
# log4j.appender.A2.layout=org.apache.log4j.PatternLayout
# log4j.appender.A2.layout.ConversionPattern=%d{DATE} [%t] %-5p %c %x - %m%n

# log4j.logger.oDao=ERROR 
# log4j.logger.actions.ProcessFileContents=TRACE 
# log4j.logger.actions.ParameterAction=ERROR
# log4j.logger.actions.IDA=ERROR
# log4j.logger.actions.Worker=ERROR

active.days=7
ftp.directory=/pabbto/3rdparty/ETL/landing/
file.move.process.port=1975
sleep.cycle.time=60000
wait.before.file.move=30000
wait.after.file.drop=-5
wrong_system_serial_no=100

##Log Properties
log4j.configuration.file=log4j.configurationFile
log.file.path=log4j2.xml
Dlog4j.configuration=log4j2.xml
Dlog4j.configuration.path=log4j2.xml
